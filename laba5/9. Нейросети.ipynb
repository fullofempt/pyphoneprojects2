{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Простая нейросеть"
      ],
      "metadata": {
        "id": "uEfm9zsfR2mt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1garAoXu2tH7"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Создаем данные для обучения\n",
        "x_train = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "y_train = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20])\n",
        "\n",
        "# Используем MinMaxScaler для масштабирования данных\n",
        "scaler = MinMaxScaler()\n",
        "x_train = scaler.fit_transform(x_train.reshape(-1, 1))\n",
        "y_train = scaler.fit_transform(y_train.reshape(-1, 1))\n",
        "\n",
        "# Создаем модель\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# Обучаем модель\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=1)\n",
        "\n",
        "# Масштабируем тестовые данные\n",
        "x_test = np.array([11, 12, 13, 14, 15])\n",
        "x_test = scaler.transform(x_test.reshape(-1, 1))\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "print(y_pred)\n",
        "print(scaler.inverse_transform(y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Нейросеть для бостонского датасета"
      ],
      "metadata": {
        "id": "8xDYZnRnSNWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "# Загрузим датасет с ценами на недвижимость в Бостоне\n",
        "boston = load_boston()\n",
        "\n",
        "# Разделим данные на признаки и целевую переменную\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Нормализуем признаки\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y.reshape(-1, 1))\n",
        "\n",
        "# Разделим данные на обучающую и тестовую выборку\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Создадим модель нейронной сети\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Обучаем модель\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Оценим качество модели на тестовых данных\n",
        "mse = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Root Mean Squared Error:', np.sqrt(mse))\n"
      ],
      "metadata": {
        "id": "uwgT2tBm48zb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функция для создания нейросети произвольной конфигурации"
      ],
      "metadata": {
        "id": "NdS_mnI4S03P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def create_sequential_model(layer_sizes, input_shape):\n",
        "    model = Sequential()\n",
        "    for i, size in enumerate(layer_sizes):\n",
        "        if i == 0:\n",
        "            model.add(Dense(size, input_shape=(input_shape,), activation='relu'))\n",
        "        else:\n",
        "            model.add(Dense(size, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "layer_sizes = [1024, 512, 256, 128]\n",
        "input_shape = X_train.shape[1]\n",
        "\n",
        "model = create_sequential_model(layer_sizes, input_shape)\n"
      ],
      "metadata": {
        "id": "OpWhwPIvGcU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "5hTG91BkKKYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=160, batch_size=32, verbose=1)\n",
        "\n",
        "# Оценим качество модели на тестовых данных\n",
        "mse = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Root Mean Squared Error:', np.sqrt(mse))"
      ],
      "metadata": {
        "id": "AB6yqESELJ_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}