import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º TensorFlow
def setup_gpu():
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ GPU –¥–ª—è TensorFlow"""
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            # –†–∞–∑—Ä–µ—à–∞–µ–º —Ä–æ—Å—Ç –ø–∞–º—è—Ç–∏ GPU
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {gpus}")
            return True
        except RuntimeError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ GPU: {e}")
            return False
    else:
        print("‚ö†Ô∏è GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
        return False

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º GPU –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
GPU_AVAILABLE = setup_gpu()

class CatDogClassifier:
    def __init__(self):
        self.model = None
        self.history = None
        self.class_names = ['cat', 'dog']
        self.img_size = (150, 150)
        self.use_generator = True  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        
    def build_improved_model(self):
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"""
        self.model = Sequential([
            # –ü–µ—Ä–≤—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
            Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
            BatchNormalization(),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # –í—Ç–æ—Ä–æ–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
            Conv2D(64, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # –¢—Ä–µ—Ç–∏–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
            Conv2D(128, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Å–≤–µ—Ä—Ç–æ—á–Ω—ã–π –±–ª–æ–∫
            Conv2D(256, (3, 3), activation='relu'),
            BatchNormalization(),
            MaxPooling2D(2, 2),
            Dropout(0.25),
            
            # –ü–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–µ —Å–ª–æ–∏
            Flatten(),
            Dense(512, activation='relu'),
            BatchNormalization(),
            Dropout(0.5),
            
            Dense(256, activation='relu'),
            BatchNormalization(),
            Dropout(0.3),
            
            Dense(1, activation='sigmoid')
        ])
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å learning rate
        optimizer = Adam(learning_rate=0.001)
        
        self.model.compile(
            optimizer=optimizer,
            loss='binary_crossentropy',
            metrics=['accuracy', 'precision', 'recall']
        )
        
        return self.model
    
    def check_data_balance(self, data_dir):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ –¥–∞–Ω–Ω—ã—Ö"""
        cat_dir = os.path.join(data_dir, 'cat')
        dog_dir = os.path.join(data_dir, 'dog')
        
        cat_count = len([f for f in os.listdir(cat_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]) if os.path.exists(cat_dir) else 0
        dog_count = len([f for f in os.listdir(dog_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]) if os.path.exists(dog_dir) else 0
        
        print(f"üê± –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∫–æ—à–µ–∫: {cat_count}")
        print(f"üê∂ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–æ–±–∞–∫: {dog_count}")
        
        if cat_count == 0 or dog_count == 0:
            raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –æ–¥–Ω–æ–π –∏–∑ –ø–∞–ø–æ–∫")
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤
        total = cat_count + dog_count
        weight_for_cat = total / (2 * cat_count)
        weight_for_dog = total / (2 * dog_count)
        
        class_weights = {0: weight_for_cat, 1: weight_for_dog}
        print(f"‚öñÔ∏è –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {class_weights}")
        
        return class_weights, cat_count, dog_count
    
    def create_data_generators(self, data_dir, batch_size=32):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        train_datagen = ImageDataGenerator(
            rescale=1./255,
            rotation_range=30,
            width_shift_range=0.2,
            height_shift_range=0.2,
            shear_range=0.2,
            zoom_range=0.2,
            horizontal_flip=True,
            brightness_range=[0.8, 1.2],
            fill_mode='nearest',
            validation_split=0.2
        )
        
        # –¢–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        val_datagen = ImageDataGenerator(
            rescale=1./255,
            validation_split=0.2
        )
        
        train_generator = train_datagen.flow_from_directory(
            data_dir,
            target_size=self.img_size,
            batch_size=batch_size,
            class_mode='binary',
            subset='training',
            shuffle=True
        )
        
        validation_generator = val_datagen.flow_from_directory(
            data_dir,
            target_size=self.img_size,
            batch_size=batch_size,
            class_mode='binary',
            subset='validation',
            shuffle=False
        )
        
        return train_generator, validation_generator
    
    def train_with_generator(self, data_dir, epochs=50, batch_size=32):
        """–û–±—É—á–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ (—ç–∫–æ–Ω–æ–º–Ω–æ –ø–æ –ø–∞–º—è—Ç–∏)"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –¥–∞–Ω–Ω—ã—Ö
        class_weights, cat_count, dog_count = self.check_data_balance(data_dir)
        
        # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã
        train_generator, validation_generator = self.create_data_generators(data_dir, batch_size)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º steps
        train_steps = train_generator.samples // batch_size
        val_steps = validation_generator.samples // batch_size
        
        print(f"üìä Train steps: {train_steps}, Validation steps: {val_steps}")
        
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –∫–æ–ª–±—ç–∫–∏
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True, verbose=1),
            ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-7, verbose=1),
            ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)
        ]
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        self.build_improved_model()
        
        # –û–±—É—á–µ–Ω–∏–µ —Å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞–º–∏
        self.history = self.model.fit(
            train_generator,
            steps_per_epoch=train_steps,
            epochs=epochs,
            validation_data=validation_generator,
            validation_steps=val_steps,
            callbacks=callbacks,
            class_weight=class_weights,
            verbose=1
        )
        
        # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
        self.evaluate_with_generator(validation_generator)
        
        return self.history
    
    def evaluate_with_generator(self, validation_generator):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞"""
        # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
        val_loss, val_accuracy, val_precision, val_recall = self.model.evaluate(
            validation_generator, verbose=0
        )
        
        print("=" * 50)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø:")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy): {val_accuracy:.4f}")
        print(f"Precision: {val_precision:.4f}")
        print(f"Recall: {val_recall:.4f}")
        print(f"–ü–æ—Ç–µ—Ä–∏ (Loss): {val_loss:.4f}")
        
        # –î–ª—è confusion matrix –Ω—É–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        self.generate_confusion_matrix(validation_generator)
    
    def generate_confusion_matrix(self, validation_generator):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è confusion matrix –ø–æ —á–∞—Å—Ç—è–º"""
        print("\nüìã –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Confusion Matrix...")
        
        y_true = []
        y_pred = []
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
        validation_generator.reset()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        for i in range(validation_generator.samples // validation_generator.batch_size + 1):
            try:
                X_batch, y_batch = validation_generator.next()
                preds = self.model.predict(X_batch, verbose=0)
                y_true.extend(y_batch)
                y_pred.extend((preds > 0.5).astype(int).flatten())
            except StopIteration:
                break
        
        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        print("üìä Confusion Matrix:")
        print(cm)
        
        # Classification report
        print("\nüìã Classification Report:")
        print(classification_report(y_true, y_pred, target_names=['Cats', 'Dogs']))
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è confusion matrix
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                    xticklabels=['Cats', 'Dogs'], 
                    yticklabels=['Cats', 'Dogs'])
        plt.title('Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.show()
    
    def train(self, data_dir, epochs=50, batch_size=32, validation_split=0.2):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã)"""
        return self.train_with_generator(data_dir, epochs, batch_size)
    
    def predict_image(self, image_path):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        img = Image.open(image_path).convert('RGB')
        img = img.resize(self.img_size)
        img_array = np.array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)
        
        prediction = self.model.predict(img_array, verbose=0)[0][0]
        class_idx = 1 if prediction > 0.5 else 0
        confidence = prediction if class_idx == 1 else 1 - prediction
        
        return self.class_names[class_idx], confidence
    
    def save_model(self, filepath):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if self.model:
            self.model.save(filepath)
    
    def load_model(self, filepath):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        self.model = load_model(filepath)
    
    def plot_training_history(self):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        if self.history is None:
            raise ValueError("–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # Accuracy
        ax1.plot(self.history.history['accuracy'], label='Training Accuracy')
        ax1.plot(self.history.history['val_accuracy'], label='Validation Accuracy')
        ax1.set_title('Model Accuracy')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Accuracy')
        ax1.legend()
        ax1.grid(True)
        
        # Loss
        ax2.plot(self.history.history['loss'], label='Training Loss')
        ax2.plot(self.history.history['val_loss'], label='Validation Loss')
        ax2.set_title('Model Loss')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Loss')
        ax2.legend()
        ax2.grid(True)
        
        # Precision
        if 'precision' in self.history.history:
            ax3.plot(self.history.history['precision'], label='Training Precision')
            ax3.plot(self.history.history['val_precision'], label='Validation Precision')
            ax3.set_title('Model Precision')
            ax3.set_xlabel('Epoch')
            ax3.set_ylabel('Precision')
            ax3.legend()
            ax3.grid(True)
        
        # Recall
        if 'recall' in self.history.history:
            ax4.plot(self.history.history['recall'], label='Training Recall')
            ax4.plot(self.history.history['val_recall'], label='Validation Recall')
            ax4.set_title('Model Recall')
            ax4.set_xlabel('Epoch')
            ax4.set_ylabel('Recall')
            ax4.legend()
            ax4.grid(True)
        
        plt.tight_layout()
        plt.show()

# –ö–ª–∞—Å—Å GUI –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π (–∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏)
# [–ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω—ã–π –∫–æ–¥ –∫–ª–∞—Å—Å–∞ GUI]

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    root = tk.Tk()
    app = GUI(root)
    root.mainloop()

if __name__ == "__main__":
    main()